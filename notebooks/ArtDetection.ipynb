{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOt4lwoZGmlhjVTp52+p7BY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"DZBzfSxs6e1C"},"outputs":[],"source":["!pip install torch torchvision numpy matplotlib scikit-learn tqdm\n","\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","from tqdm import tqdm\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import models, transforms\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Menggunakan device: {device}\")"]},{"cell_type":"code","source":["from google.colab import drive\n","import os\n","\n","drive.mount('/content/drive')\n","zip_path = '/content/drive/MyDrive/dataset_lukisan.zip'\n","\n","extract_path = '/content/temp_dataset'\n","\n","if not os.path.exists(extract_path):\n","    print(f\"Sedang mengekstrak {zip_path} ke {extract_path}...\")\n","    !unzip -q \"$zip_path\" -d \"$extract_path\"\n","    print(\"Ekstraksi selesai!\")\n","else:\n","    print(\"Folder dataset sudah ada. Melewati proses ekstraksi.\")\n","\n","DATA_DIR = extract_path\n","\n","TRAIN_DIR = os.path.join(DATA_DIR, 'train')\n","VAL_DIR = os.path.join(DATA_DIR, 'val')\n","\n","print(f\"Isi folder DATA_DIR ({DATA_DIR}):\")\n","print(os.listdir(DATA_DIR))"],"metadata":{"id":"mtH9IrcE9m3O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class FFTTransform:\n","    def __call__(self, img):\n","        #Grayscale\n","        img_gray = img.convert('L')\n","        img_array = np.array(img_gray)\n","\n","        #Fast Fourier Transform\n","        f = np.fft.fft2(img_array)\n","        fshift = np.fft.fftshift(f) #frekuensi rendah ke tengah\n","\n","        #Hitung Magnitude Spectrum\n","        magnitude_spectrum = 20 * np.log(np.abs(fshift) + 1e-8)\n","\n","        #Normalisasi ke range 0-255\n","        magnitude_spectrum = np.nan_to_num(magnitude_spectrum)\n","        ms_min = np.min(magnitude_spectrum)\n","        ms_max = np.max(magnitude_spectrum)\n","\n","        # Scaling min-max\n","        if ms_max - ms_min > 0:\n","            img_fft = 255 * (magnitude_spectrum - ms_min) / (ms_max - ms_min)\n","        else:\n","            img_fft = np.zeros_like(magnitude_spectrum)\n","\n","        img_fft = img_fft.astype(np.uint8)\n","\n","        #Konversi PIL Image\n","        img_fft_pil = Image.fromarray(img_fft).convert(\"RGB\")\n","\n","        return img_fft_pil\n","\n","def visualize_fft_sample(image_path):\n","    img = Image.open(image_path)\n","    transformer = FFTTransform()\n","    fft_img = transformer(img)\n","\n","    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n","    ax[0].imshow(img)\n","    ax[0].set_title(\"Original Image\")\n","    ax[1].imshow(fft_img)\n","    ax[1].set_title(\"FFT Spectrum Input\")\n","    plt.show()\n","\n","visualize_fft_sample('/content/drive/MyDrive/dataset_lukisan/train/ai/sample.jpg')"],"metadata":{"id":"o_ji31r49vy1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.Resize((224, 224)),\n","        FFTTransform(),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406],\n","                             [0.229, 0.224, 0.225])\n","    ]),\n","    'val': transforms.Compose([\n","        transforms.Resize((224, 224)),\n","        FFTTransform(),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406],\n","                             [0.229, 0.224, 0.225])\n","    ]),\n","}\n","\n","image_datasets = {\n","    'train': torchvision.datasets.ImageFolder(TRAIN_DIR, data_transforms['train']),\n","    'val': torchvision.datasets.ImageFolder(VAL_DIR, data_transforms['val'])\n","}\n","\n","dataloaders = {\n","    'train': DataLoader(image_datasets['train'], batch_size=32, shuffle=True, num_workers=2),\n","    'val': DataLoader(image_datasets['val'], batch_size=32, shuffle=False, num_workers=2)\n","}\n","\n","dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n","class_names = image_datasets['train'].classes\n","\n","print(f\"Classes: {class_names}\")\n","print(f\"Training samples: {dataset_sizes['train']}\")\n","print(f\"Validation samples: {dataset_sizes['val']}\")"],"metadata":{"id":"-A9fq-k49wu7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n","\n","# Freeze sebagian layer awal (opsional, tapi disarankan agar training lebih cepat)\n","# Jika dataset besar (22k), kita bisa unfreeze semua atau freeze sedikit saja.\n","# Di sini kita biarkan unfreezed agar model belajar fitur frekuensi dari awal.\n","# for param in model.features.parameters():\n","#     param.requires_grad = False\n","\n","# Ganti Classifier Head terakhir\n","# EfficientNet-B0 classifier input features biasanya 1280\n","num_ftrs = model.classifier[1].in_features\n","\n","model.classifier = nn.Sequential(\n","    nn.Dropout(p=0.2, inplace=True),\n","    nn.Linear(num_ftrs, 2)\n",")\n","\n","model = model.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.0001)"],"metadata":{"id":"lY9uEnaD-XUc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_model(model, criterion, optimizer, num_epochs=10):\n","    best_acc = 0.0\n","\n","    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n","\n","    for epoch in range(num_epochs):\n","        print(f'Epoch {epoch+1}/{num_epochs}')\n","        print('-' * 10)\n","\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()\n","            else:\n","                model.eval()\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            #Iterasi data\n","            for inputs, labels in tqdm(dataloaders[phase], desc=phase):\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                optimizer.zero_grad()\n","\n","                #Forward\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    _, preds = torch.max(outputs, 1)\n","                    loss = criterion(outputs, labels)\n","\n","                    #Backward + Optimize\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","\n","            epoch_loss = running_loss / dataset_sizes[phase]\n","            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n","\n","            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n","\n","            if phase == 'train':\n","                history['train_loss'].append(epoch_loss)\n","                history['train_acc'].append(epoch_acc.item())\n","            else:\n","                history['val_loss'].append(epoch_loss)\n","                history['val_acc'].append(epoch_acc.item())\n","\n","                if epoch_acc > best_acc:\n","                    best_acc = epoch_acc\n","                    torch.save(model.state_dict(), 'best_model_efficientnet_fft.pth')\n","\n","    print(f'Best Val Acc: {best_acc:.4f}')\n","    return model, history\n","\n","model_trained, history = train_model(model, criterion, optimizer, num_epochs=30)"],"metadata":{"id":"tvgMxWhF-ZKe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(12, 4))\n","plt.subplot(1, 2, 1)\n","plt.plot(history['train_acc'], label='Train Acc')\n","plt.plot(history['val_acc'], label='Val Acc')\n","plt.title('Accuracy')\n","plt.legend()\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(history['train_loss'], label='Train Loss')\n","plt.plot(history['val_loss'], label='Val Loss')\n","plt.title('Loss')\n","plt.legend()\n","plt.show()\n","\n","from google.colab import files\n","files.download('bestModelV1.pth')"],"metadata":{"id":"ymTO5nMH-a52"},"execution_count":null,"outputs":[]}]}