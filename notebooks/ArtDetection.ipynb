{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1QJvBhAfU-a1zPGDd-HiRZCRq98gXeZTW","timestamp":1767692089420}],"gpuType":"T4","mount_file_id":"1QJvBhAfU-a1zPGDd-HiRZCRq98gXeZTW","authorship_tag":"ABX9TyNG5EiOvk8sQvqhntF0R1lu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"DZBzfSxs6e1C"},"outputs":[],"source":["import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","from tqdm import tqdm\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import models, transforms, datasets\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Menggunakan device: {device}\")"]},{"cell_type":"code","source":["from google.colab import drive\n","import os\n","\n","drive.mount('/content/drive')\n","\n","zip_train_path = '/content/drive/MyDrive/dataset/train.zip'\n","zip_val_path   = '/content/drive/MyDrive/dataset/val.zip'\n","\n","base_dir  = '/content/temp_dataset'\n","train_dir = os.path.join(base_dir, 'train')\n","val_dir   = os.path.join(base_dir, 'val')\n","\n","def extract_zip(zip_path, dest_path):\n","    if not os.path.exists(dest_path):\n","        print(f\"Membuat folder {dest_path}\")\n","        os.makedirs(dest_path, exist_ok=True)\n","\n","        print(f\"Mengekstrak {zip_path} ke {dest_path}\")\n","        !unzip -q \"$zip_path\" -d \"$dest_path\"\n","        print(f\"Selesai mengekstrak ke {dest_path}\")\n","    else:\n","        print(f\"Folder {dest_path} sudah ada. Melewati ekstraksi.\")\n","\n","if os.path.exists(zip_train_path):\n","    extract_zip(zip_train_path, train_dir)\n","else:\n","    print(f\"PERINGATAN: File {zip_train_path} tidak ditemukan di Drive!\")\n","\n","if os.path.exists(zip_val_path):\n","    extract_zip(zip_val_path, val_dir)\n","else:\n","    print(f\"PERINGATAN: File {zip_val_path} tidak ditemukan di Drive!\")\n","\n","DATA_DIR = base_dir\n","TRAIN_DIR = train_dir\n","VAL_DIR = val_dir\n","\n","print(\"\\n--- Pengecekan Struktur Folder ---\")\n","if os.path.exists(TRAIN_DIR):\n","    print(f\"Isi {TRAIN_DIR}: {os.listdir(TRAIN_DIR)}\")\n","\n","    subfolders = os.listdir(TRAIN_DIR)\n","    if len(subfolders) > 0:\n","        first_sub = os.path.join(TRAIN_DIR, subfolders[0])\n","        if os.path.isdir(first_sub):\n","             print(f\"Contoh isi dalam '{subfolders[0]}': {os.listdir(first_sub)[:5]}\")\n","\n","if os.path.exists(VAL_DIR):\n","    print(f\"Isi {VAL_DIR}: {os.listdir(VAL_DIR)}\")"],"metadata":{"id":"mtH9IrcE9m3O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767776715204,"user_tz":-420,"elapsed":2820,"user":{"displayName":"Administrator","userId":"13685682978790530135"}},"outputId":"9cf5f367-33c6-40b4-e2e8-24ae503e6e5a"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Folder /content/temp_dataset/train sudah ada. Melewati ekstraksi.\n","Folder /content/temp_dataset/val sudah ada. Melewati ekstraksi.\n","\n","--- Pengecekan Struktur Folder ---\n","Isi /content/temp_dataset/train: ['train']\n","Contoh isi dalam 'train': ['real', '.DS_Store', 'ai']\n","Isi /content/temp_dataset/val: ['val']\n"]}]},{"cell_type":"code","source":["import os\n","import shutil\n","\n","def remove_macos_artifacts(path):\n","    print(f\"Membersihkan artefak MacOS di: {path}\")\n","    count_files = 0\n","    count_folders = 0\n","\n","    for root, dirs, files in os.walk(path):\n","        if '__MACOSX' in dirs:\n","            rm_path = os.path.join(root, '__MACOSX')\n","            try:\n","                shutil.rmtree(rm_path)\n","                count_folders += 1\n","            except Exception as e:\n","                print(f\"Gagal hapus {rm_path}: {e}\")\n","            dirs.remove('__MACOSX')\n","\n","        for file in files:\n","            if file.startswith('._'):\n","                file_path = os.path.join(root, file)\n","                try:\n","                    os.remove(file_path)\n","                    count_files += 1\n","                except Exception as e:\n","                    print(f\"Gagal hapus {file_path}: {e}\")\n","\n","    print(f\"Selesai! Dihapus: {count_folders} folder __MACOSX dan {count_files} file metadata.\")\n","\n","remove_macos_artifacts(DATA_DIR)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QtNQ__tGdUIX","executionInfo":{"status":"ok","timestamp":1767776740304,"user_tz":-420,"elapsed":24,"user":{"displayName":"Administrator","userId":"13685682978790530135"}},"outputId":"f259bb3b-a0de-46f1-a772-b8a4a369d064"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Membersihkan artefak MacOS di: /content/temp_dataset\n","Selesai! Dihapus: 0 folder __MACOSX dan 0 file metadata.\n"]}]},{"cell_type":"code","source":["import os\n","from PIL import Image\n","\n","def validate_and_clean_images(root_dir):\n","    print(f\"Memulai pengecekan integritas gambar di: {root_dir}\")\n","    print(\"Proses ini mungkin memakan waktu 1-2 menit...\")\n","\n","    bad_files = 0\n","    checked_files = 0\n","\n","    for root, dirs, files in os.walk(root_dir):\n","        for file in files:\n","            if file.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff')):\n","                file_path = os.path.join(root, file)\n","                checked_files += 1\n","\n","                try:\n","                    with Image.open(file_path) as img:\n","                        img.verify()\n","                except (IOError, SyntaxError, Image.UnidentifiedImageError) as e:\n","                    print(f\"File rusak ditemukan: {file_path}\")\n","                    try:\n","                        os.remove(file_path)\n","                        print(f\"Berhasil dihapus\")\n","                        bad_files += 1\n","                    except Exception as del_err:\n","                        print(f\"Gagal menghapus: {del_err}\")\n","\n","    print(\"-\" * 30)\n","    print(f\"Total diperiksa: {checked_files}\")\n","    print(f\"Total file rusak dihapus: {bad_files}\")\n","\n","validate_and_clean_images(DATA_DIR)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W_kyGHlmgPIq","executionInfo":{"status":"ok","timestamp":1767776744031,"user_tz":-420,"elapsed":1524,"user":{"displayName":"Administrator","userId":"13685682978790530135"}},"outputId":"cacdbc62-749c-447e-fdfe-6a6a82691fcc"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Memulai pengecekan integritas gambar di: /content/temp_dataset\n","Proses ini mungkin memakan waktu 1-2 menit...\n","------------------------------\n","Total diperiksa: 22512\n","Total file rusak dihapus: 0\n"]}]},{"cell_type":"code","source":["class FFTTransform:\n","    def __call__(self, img):\n","\n","        img_gray = img.convert('L')\n","        img_array = np.array(img_gray)\n","\n","        f = np.fft.fft2(img_array)\n","        fshift = np.fft.fftshift(f)\n","\n","        magnitude_spectrum = 20 * np.log(np.abs(fshift) + 1e-8)\n","\n","        magnitude_spectrum = np.nan_to_num(magnitude_spectrum)\n","        ms_min = np.min(magnitude_spectrum)\n","        ms_max = np.max(magnitude_spectrum)\n","\n","        if ms_max - ms_min > 0:\n","            img_fft = 255 * (magnitude_spectrum - ms_min) / (ms_max - ms_min)\n","        else:\n","            img_fft = np.zeros_like(magnitude_spectrum)\n","\n","        img_fft = img_fft.astype(np.uint8)\n","\n","        return Image.fromarray(img_fft).convert(\"RGB\")\n","\n","data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.Resize((224, 224)),\n","        FFTTransform(),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    'val': transforms.Compose([\n","        transforms.Resize((224, 224)),\n","        FFTTransform(),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","}\n","\n","image_datasets = {\n","    'train': datasets.ImageFolder(os.path.join(TRAIN_DIR, 'train'), data_transforms['train']),\n","    'val': datasets.ImageFolder(os.path.join(VAL_DIR, 'val'), data_transforms['val'])\n","}\n","\n","dataloaders = {\n","    'train': DataLoader(image_datasets['train'], batch_size=32, shuffle=True),\n","    'val': DataLoader(image_datasets['val'], batch_size=32, shuffle=False)\n","}\n","\n","class_names = image_datasets['train'].classes\n","print(f\"URUTAN KELAS: {class_names}\")\n","for i, class_name in enumerate(class_names):\n","    print(f\"Index {i} = {class_name}\")\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"o_ji31r49vy1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n","\n","num_ftrs = model.classifier[1].in_features\n","model.classifier = nn.Sequential(\n","    nn.Dropout(0.2),\n","    nn.Linear(num_ftrs, 2)\n",")\n","model = model.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.0001)\n","\n","def train_model(model, num_epochs=10):\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        print(f'Epoch {epoch+1}/{num_epochs}')\n","\n","        for phase in ['train', 'val']:\n","            if phase == 'train': model.train()\n","            else: model.eval()\n","\n","            running_corrects = 0\n","\n","            for inputs, labels in tqdm(dataloaders[phase], desc=phase):\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","                optimizer.zero_grad()\n","\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    _, preds = torch.max(outputs, 1)\n","                    loss = criterion(outputs, labels)\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                running_corrects += torch.sum(preds == labels.data)\n","\n","            epoch_acc = running_corrects.double() / len(image_datasets[phase])\n","            print(f'{phase} Acc: {epoch_acc:.4f}')\n","\n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                torch.save(model.state_dict(), 'best_model_efficientnet_fft.pth')\n","                print(\"Model saved!\")\n","\n","train_model(model, num_epochs=30)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ci79N6aqgWh2","outputId":"0e82eb77-d133-4c7d-df94-b386e577d0d9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20.5M/20.5M [00:00<00:00, 171MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n"]},{"output_type":"stream","name":"stderr","text":["train:  83%|████████▎ | 553/666 [02:23<00:32,  3.46it/s]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  warnings.warn(\n","train: 100%|██████████| 666/666 [02:49<00:00,  3.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Acc: 0.9230\n"]},{"output_type":"stream","name":"stderr","text":["val: 100%|██████████| 38/38 [00:06<00:00,  5.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val Acc: 0.9758\n","Model saved!\n","Epoch 2/30\n"]},{"output_type":"stream","name":"stderr","text":["train: 100%|██████████| 666/666 [02:38<00:00,  4.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Acc: 0.9683\n"]},{"output_type":"stream","name":"stderr","text":["val: 100%|██████████| 38/38 [00:07<00:00,  5.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val Acc: 0.9750\n","Epoch 3/30\n"]},{"output_type":"stream","name":"stderr","text":["train: 100%|██████████| 666/666 [02:38<00:00,  4.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Acc: 0.9804\n"]},{"output_type":"stream","name":"stderr","text":["val: 100%|██████████| 38/38 [00:06<00:00,  5.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val Acc: 0.9833\n","Model saved!\n","Epoch 4/30\n"]},{"output_type":"stream","name":"stderr","text":["train: 100%|██████████| 666/666 [02:39<00:00,  4.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Acc: 0.9843\n"]},{"output_type":"stream","name":"stderr","text":["val: 100%|██████████| 38/38 [00:07<00:00,  5.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val Acc: 0.9708\n","Epoch 5/30\n"]},{"output_type":"stream","name":"stderr","text":["train:  51%|█████     | 337/666 [01:19<01:41,  3.25it/s]"]}]},{"cell_type":"code","source":["plt.figure(figsize=(14, 5))\n","\n","plt.subplot(1, 2, 1)\n","plt.plot(history['train_acc'], label='Train Accuracy', marker='o')\n","plt.plot(history['val_acc'], label='Validation Accuracy', marker='o')\n","plt.title('Training vs Validation Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.grid(True)\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(history['train_loss'], label='Train Loss', marker='o')\n","plt.plot(history['val_loss'], label='Validation Loss', marker='o')\n","plt.title('Training vs Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.grid(True)\n","\n","plt.show()\n","\n","torch.save(model.state_dict(), 'final_model_efficientnet_fft.pth')\n","print(\"Model berhasil disimpan.\")\n","\n","from google.colab import files\n","\n","if os.path.exists('best_model_efficientnet_fft.pth'):\n","    files.download('best_model_efficientnet_fft.pth')\n","else:\n","    print(\"File best_model tidak ditemukan, download model final saja.\")\n","    files.download('final_model_efficientnet_fft.pth')"],"metadata":{"id":"ymTO5nMH-a52"},"execution_count":null,"outputs":[]}]}