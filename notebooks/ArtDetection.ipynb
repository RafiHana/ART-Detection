{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DZBzfSxs6e1C"
   },
   "outputs": [],
   "source": [
    "!pip install torch torchvision numpy matplotlib scikit-learn tqdm\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Menggunakan device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mtH9IrcE9m3O"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "zip_train_path = '/content/drive/MyDrive/dataset/train.zip' \n",
    "zip_val_path   = '/content/drive/MyDrive/dataset/val.zip' \n",
    "\n",
    "base_dir  = '/content/temp_dataset'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir   = os.path.join(base_dir, 'val')\n",
    "\n",
    "def extract_zip(zip_path, dest_path):\n",
    "    if not os.path.exists(dest_path):\n",
    "        print(f\"Membuat folder {dest_path}...\")\n",
    "        os.makedirs(dest_path, exist_ok=True)\n",
    "\n",
    "        print(f\"Mengekstrak {zip_path} ke {dest_path}...\")\n",
    "        !unzip -q \"$zip_path\" -d \"$dest_path\"\n",
    "        print(f\"Selesai mengekstrak ke {dest_path}\")\n",
    "    else:\n",
    "        print(f\"Folder {dest_path} lewati ekstrak\")\n",
    "\n",
    "if os.path.exists(zip_train_path):\n",
    "    extract_zip(zip_train_path, train_dir)\n",
    "else:\n",
    "    print(f\"File {zip_train_path} tidak ditemukan di Drive\")\n",
    "\n",
    "if os.path.exists(zip_val_path):\n",
    "    extract_zip(zip_val_path, val_dir)\n",
    "else:\n",
    "    print(f\"File {zip_val_path} tidak ditemukan di Drive\")\n",
    "\n",
    "DATA_DIR = base_dir\n",
    "TRAIN_DIR = train_dir\n",
    "VAL_DIR = val_dir\n",
    "\n",
    "if os.path.exists(TRAIN_DIR):\n",
    "    print(f\"Isi {TRAIN_DIR}: {os.listdir(TRAIN_DIR)}\")\n",
    "\n",
    "    subfolders = os.listdir(TRAIN_DIR)\n",
    "    if len(subfolders) > 0:\n",
    "        first_sub = os.path.join(TRAIN_DIR, subfolders[0])\n",
    "        if os.path.isdir(first_sub):\n",
    "             print(f\"Isi dalam '{subfolders[0]}': {os.listdir(first_sub)[:5]}\")\n",
    "\n",
    "if os.path.exists(VAL_DIR):\n",
    "    print(f\"Isi {VAL_DIR}: {os.listdir(VAL_DIR)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1767688439643,
     "user": {
      "displayName": "Administrator",
      "userId": "13685682978790530135"
     },
     "user_tz": -420
    },
    "id": "o_ji31r49vy1"
   },
   "outputs": [],
   "source": [
    "class FFTTransform:\n",
    "    def __call__(self, img):\n",
    "        #Grayscale\n",
    "        img_gray = img.convert('L')\n",
    "        img_array = np.array(img_gray)\n",
    "\n",
    "        #Fast Fourier Transform\n",
    "        f = np.fft.fft2(img_array)\n",
    "        fshift = np.fft.fftshift(f) #frekuensi rendah ke tengah\n",
    "\n",
    "        #Hitung Magnitude Spectrum\n",
    "        magnitude_spectrum = 20 * np.log(np.abs(fshift) + 1e-8)\n",
    "\n",
    "        #Normalisasi ke range 0-255\n",
    "        magnitude_spectrum = np.nan_to_num(magnitude_spectrum)\n",
    "        ms_min = np.min(magnitude_spectrum)\n",
    "        ms_max = np.max(magnitude_spectrum)\n",
    "\n",
    "        # Scaling min-max\n",
    "        if ms_max - ms_min > 0:\n",
    "            img_fft = 255 * (magnitude_spectrum - ms_min) / (ms_max - ms_min)\n",
    "        else:\n",
    "            img_fft = np.zeros_like(magnitude_spectrum)\n",
    "\n",
    "        img_fft = img_fft.astype(np.uint8)\n",
    "\n",
    "        #Konversi PIL Image\n",
    "        img_fft_pil = Image.fromarray(img_fft).convert(\"RGB\")\n",
    "\n",
    "        return img_fft_pil\n",
    "\n",
    "# def visualize_fft_sample(image_path):\n",
    "#     img = Image.open(image_path)\n",
    "#     transformer = FFTTransform()\n",
    "#     fft_img = transformer(img)\n",
    "\n",
    "#     fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "#     ax[0].imshow(img)\n",
    "#     ax[0].set_title(\"Original Image\")\n",
    "#     ax[1].imshow(fft_img)\n",
    "#     ax[1].set_title(\"FFT Spectrum Input\")\n",
    "#     plt.show()\n",
    "\n",
    "# visualize_fft_sample('/content/drive/MyDrive/dataset/train/train/ai/imgAI602.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 347,
     "status": "ok",
     "timestamp": 1767688719286,
     "user": {
      "displayName": "Administrator",
      "userId": "13685682978790530135"
     },
     "user_tz": -420
    },
    "id": "QtNQ__tGdUIX",
    "outputId": "6904bf65-ade7-472d-9e96-1dcef0bcdba3"
   },
   "outputs": [],
   "source": [
    "#MACOS\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def remove_macos_artifacts(path):\n",
    "    print(f\"Membersihkan MacOS di: {path}\")\n",
    "    count_files = 0\n",
    "    count_folders = 0\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        if '__MACOSX' in dirs:\n",
    "            rm_path = os.path.join(root, '__MACOSX')\n",
    "            try:\n",
    "                shutil.rmtree(rm_path)\n",
    "                count_folders += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Gagal hapus {rm_path}: {e}\")\n",
    "            dirs.remove('__MACOSX')\n",
    "\n",
    "        for file in files:\n",
    "            if file.startswith('._'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    os.remove(file_path)\n",
    "                    count_files += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Gagal hapus {file_path}: {e}\")\n",
    "\n",
    "    print(f\"Selesa hapus: {count_folders} folder __MACOSX{count_files}\")\n",
    "\n",
    "remove_macos_artifacts(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1767688733667,
     "user": {
      "displayName": "Administrator",
      "userId": "13685682978790530135"
     },
     "user_tz": -420
    },
    "id": "WPAqRK43dWXa",
    "outputId": "d0cca5ec-5a8f-4a26-ee96-b9e3657d8483"
   },
   "outputs": [],
   "source": [
    "image_datasets = {\n",
    "    'train': torchvision.datasets.ImageFolder(TRAIN_DIR, data_transforms['train']),\n",
    "    'val': torchvision.datasets.ImageFolder(VAL_DIR, data_transforms['val'])\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(image_datasets['train'], batch_size=32, shuffle=True, num_workers=2),\n",
    "    'val': DataLoader(image_datasets['val'], batch_size=32, shuffle=False, num_workers=2)\n",
    "}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "print(\"DataLoader berhasil diperbarui tanpa file sampah MacOS.\")\n",
    "print(f\"Total Train: {dataset_sizes['train']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 65,
     "status": "ok",
     "timestamp": 1767688750959,
     "user": {
      "displayName": "Administrator",
      "userId": "13685682978790530135"
     },
     "user_tz": -420
    },
    "id": "4J1OtFY8da8F",
    "outputId": "12a1db1c-bc9e-4953-9573-4ab7edb4176f"
   },
   "outputs": [],
   "source": [
    "image_datasets = {\n",
    "    'train': torchvision.datasets.ImageFolder(TRAIN_DIR, data_transforms['train']),\n",
    "    'val': torchvision.datasets.ImageFolder(VAL_DIR, data_transforms['val'])\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(image_datasets['train'], batch_size=32, shuffle=True, num_workers=2),\n",
    "    'val': DataLoader(image_datasets['val'], batch_size=32, shuffle=False, num_workers=2)\n",
    "}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "print(\"DataLoader berhasil diperbarui tanpa file sampah MacOS.\")\n",
    "print(f\"Total Train: {dataset_sizes['train']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jbxlhb52cbQX"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 166,
     "status": "ok",
     "timestamp": 1767688759021,
     "user": {
      "displayName": "Administrator",
      "userId": "13685682978790530135"
     },
     "user_tz": -420
    },
    "id": "lY9uEnaD-XUc"
   },
   "outputs": [],
   "source": [
    "model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.2, inplace=True),\n",
    "    nn.Linear(num_ftrs, 2)\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1474,
     "status": "ok",
     "timestamp": 1767689486733,
     "user": {
      "displayName": "Administrator",
      "userId": "13685682978790530135"
     },
     "user_tz": -420
    },
    "id": "W_kyGHlmgPIq",
    "outputId": "55f61c5b-800e-460a-acc9-dad34c787c65"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def validate_and_clean_images(root_dir):\n",
    "    print(f\"Memulai pengecekan integritas gambar di: {root_dir}\")\n",
    "    print(\"Proses ini mungkin memakan waktu 1-2 menit...\")\n",
    "\n",
    "    bad_files = 0\n",
    "    checked_files = 0\n",
    "\n",
    "    for root, dirs, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff')):\n",
    "                file_path = os.path.join(root, file)\n",
    "                checked_files += 1\n",
    "\n",
    "                try:\n",
    "                    with Image.open(file_path) as img:\n",
    "                        img.verify()\n",
    "                except (IOError, SyntaxError, Image.UnidentifiedImageError) as e:\n",
    "                    print(f\"File rusak ditemukan: {file_path}\")\n",
    "                    try:\n",
    "                        os.remove(file_path)\n",
    "                        print(f\"Berhasil dihapus\")\n",
    "                        bad_files += 1\n",
    "                    except Exception as del_err:\n",
    "                        print(f\"Gagal menghapus: {del_err}\")\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Total diperiksa: {checked_files}\")\n",
    "    print(f\"Total file rusak dihapus: {bad_files}\")\n",
    "\n",
    "validate_and_clean_images(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1767689501299,
     "user": {
      "displayName": "Administrator",
      "userId": "13685682978790530135"
     },
     "user_tz": -420
    },
    "id": "vqY0C19mgRlr",
    "outputId": "faf8f49a-dfe8-4e87-9a12-d15031f7652e"
   },
   "outputs": [],
   "source": [
    "image_datasets = {\n",
    "    'train': torchvision.datasets.ImageFolder(TRAIN_DIR, data_transforms['train']),\n",
    "    'val': torchvision.datasets.ImageFolder(VAL_DIR, data_transforms['val'])\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(image_datasets['train'], batch_size=32, shuffle=True, num_workers=2),\n",
    "    'val': DataLoader(image_datasets['val'], batch_size=32, shuffle=False, num_workers=2)\n",
    "}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "print(f\"Dataset di-refresh. Total Train: {dataset_sizes['train']}, Val: {dataset_sizes['val']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1249584,
     "status": "ok",
     "timestamp": 1767690765735,
     "user": {
      "displayName": "Administrator",
      "userId": "13685682978790530135"
     },
     "user_tz": -420
    },
    "id": "ci79N6aqgWh2",
    "outputId": "5abddbbe-5b60-4a16-da6b-a681615fb1df"
   },
   "outputs": [],
   "source": [
    "model_trained, history = train_model(model, criterion, optimizer, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432
    },
    "executionInfo": {
     "elapsed": 324,
     "status": "ok",
     "timestamp": 1767690956417,
     "user": {
      "displayName": "Administrator",
      "userId": "13685682978790530135"
     },
     "user_tz": -420
    },
    "id": "ymTO5nMH-a52",
    "outputId": "304f7546-f46b-4940-f8dd-7c267bd9729b"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_acc'], label='Train Accuracy', marker='o')\n",
    "plt.plot(history['val_acc'], label='Validation Accuracy', marker='o')\n",
    "plt.title('Training vs Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['train_loss'], label='Train Loss', marker='o')\n",
    "plt.plot(history['val_loss'], label='Validation Loss', marker='o')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "torch.save(model.state_dict(), 'final_model_efficientnet_fft.pth')\n",
    "print(\"Model berhasil disimpan.\")\n",
    "\n",
    "from google.colab import files\n",
    "print(\"Mempersiapkan download model terbaik...\")\n",
    "\n",
    "if os.path.exists('best_model_efficientnet_fft.pth'):\n",
    "    files.download('best_model_efficientnet_fft.pth')\n",
    "else:\n",
    "    print(\"File best_model tidak ditemukan, download model final saja.\")\n",
    "    files.download('final_model_efficientnet_fft.pth')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNKl5ypHQG4MKdAXXbpZnVd",
   "gpuType": "T4",
   "mount_file_id": "1QJvBhAfU-a1zPGDd-HiRZCRq98gXeZTW",
   "provenance": [
    {
     "file_id": "1QJvBhAfU-a1zPGDd-HiRZCRq98gXeZTW",
     "timestamp": 1767692089420
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
